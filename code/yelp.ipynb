{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by  import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction():\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    driver.implicitly_wait(10)\n",
    "    driver.set_script_timeout(180)\n",
    "    driver.set_page_load_timeout(10)\n",
    "    driver.get('https://www.yelp.com/')\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "    text_input = driver.find_element(By.CSS_SELECTOR, \"input[id='search_description']\")\n",
    "    text_input.send_keys('Indian \\n')\n",
    "    # Click the element\n",
    "    time.sleep(5)\n",
    "    base_directory = '/Users/himanishprakash/Desktop/DDR/Yelp_data'\n",
    "    number_of_page = 10 \n",
    "    for i in range(number_of_page):\n",
    "        \n",
    "        page_source = driver.page_source\n",
    "        page_file_path = os.path.join(base_directory, f'yelp_indian_{i+1}.html')\n",
    "        \n",
    "        with open(page_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(page_source)\n",
    "        \n",
    "        ##  Clicking on all time Steals leader      \n",
    "        page_1 = driver.find_element(By.CSS_SELECTOR, \"button[class='pagination-button__09f24__kbFYf css-x61rbl']\")\n",
    "        page_1.click()\n",
    "        time.sleep(6)\n",
    "        \n",
    "        \n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_load():\n",
    "    # Specify the directory containing your HTML files\n",
    "    directory_path = '/Users/himanishprakash/Desktop/DDR/Yelp_data'\n",
    "\n",
    "    # List all files in the directory\n",
    "    html_files = [f for f in os.listdir(directory_path) if f.endswith('.html')]\n",
    "\n",
    "    # Sort the files by name to maintain order, if necessary\n",
    "    html_files.sort()\n",
    "    extracted_values = []\n",
    "\n",
    "    # Loop through each HTML file\n",
    "    for html_file in html_files:\n",
    "        # Construct the full path to the HTML file\n",
    "        file_path = os.path.join(directory_path, html_file)\n",
    "        \n",
    "        # Open and read the HTML file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            html_content = file.read()\n",
    "        \n",
    "        # Process the HTML content, e.g., using BeautifulSoup to parse it\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        # Find all elements matching the given CSS selector\n",
    "        Restaurant_name = soup.select('a.css-19v1rkv')\n",
    "        location = soup.select('span.css-chan6m')\n",
    "        for name, loc in zip(Restaurant_name, location):\n",
    "            extracted_values.append({'Restaurant Name': name.text.strip(), 'Location': loc.text.strip()})\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(extracted_values)\n",
    "\n",
    "    # Drop duplicates based on both 'Restaurant Name' and 'Location'\n",
    "    df_unique = df.drop_duplicates(subset=['Restaurant Name', 'Location'])\n",
    "\n",
    "    df_unique = df_unique.iloc[3:]\n",
    "    df_unique = df_unique[~df_unique['Location'].str.contains('reviews')]\n",
    "    df_unique = df_unique[~df_unique['Location'].str.contains('review')]\n",
    "    # Define the path for the CSV file to save the unique values\n",
    "    csv_file_path = '/Users/himanishprakash/Desktop/DDR/Yelp_data/extracted_values.csv'\n",
    "\n",
    "    # Save the DataFrame with unique values to a CSV file\n",
    "    df_unique.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    print(f\"Unique restaurant names and locations saved to {csv_file_path}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique restaurant names and locations saved to /Users/himanishprakash/Desktop/DDR/Yelp_data/extracted_values.csv\n"
     ]
    }
   ],
   "source": [
    "extraction()\n",
    "transformation_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
